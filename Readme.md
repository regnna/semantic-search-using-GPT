---
title: Semantic Search Revived
emoji: ğŸ”
colorFrom: blue
colorTo: purple
sdk: docker
app_port: 7860
---

# Semantic Search (Token-Free Edition)

Local embeddings + Local LLM = Zero API costs, 100% privacy

# ğŸ” Semantic Search Revived

**A 100% local, privacy-first semantic search engine with AI-powered answers. No API keys, no cloud dependencies, no token costs.**

![Python](https://img.shields.io/badge/Python-3.11-blue)
![Streamlit](https://img.shields.io/badge/Streamlit-1.40-red)
![License](https://img.shields.io/badge/License-MIT-green)
![Status](https://img.shields.io/badge/Status-Active-brightgreen)

---

## âœ¨ What Makes This Special?

| Feature | Traditional Approach | This Project |
|---------|---------------------|--------------|
| **Embeddings** | OpenAI API ($$$) | Local Sentence Transformers (Free) |
| **LLM Answers** | GPT-4 API ($$$) | Local Ollama (Free) |
| **Vector DB** | Pinecone/Weaviate (Cloud) | Local FAISS (Free, Fast) |
| **Privacy** | Data sent to cloud | 100% Local processing |
| **Offline Use** | Requires internet | Works completely offline |
| **Cost** | Pay per use | $0 forever |

---

## ğŸ¬ Demo
```bash

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Streamlit UI  â”‚â”€â”€â”€â”€â–¶â”‚  Document Input  â”‚â”€â”€â”€â”€â–¶â”‚  Web Scraper    â”‚
â”‚                 â”‚     â”‚  (URL/Files)     â”‚     â”‚  (BeautifulSoup)â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â–¼
â”‚   Local LLM     â”‚â—€â”€â”€â”€â”€â”‚  Context + Query â”‚     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   (Ollama)      â”‚     â”‚  Prompt Builder  â”‚â—€â”€â”€â”€â”€â”‚  Text Chunker   â”‚
â”‚   Llama 3.2     â”‚     â”‚                  â”‚     â”‚  (2000 chars)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â–²                                               â”‚
â”‚               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â–¼
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚  FAISS Index     â”‚â—€â”€â”€â”€â”€â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  (Local Vector DB)â”‚     â”‚  MiniLM Embeddings
â”‚  384 dimensions   â”‚     â”‚  (Sentence-Transformers)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```


---

## ğŸ—ï¸ Architecture
```bash
semantic-search-revived/
â”œâ”€â”€ ğŸ“„ app.py                 # Main Streamlit application
â”œâ”€â”€ ğŸ” vector_search.py       # FAISS vector database operations
â”œâ”€â”€ ğŸ¤– query.py               # Ollama LLM integration
â”œâ”€â”€ ğŸ› ï¸ utils.py               # Web scraping utilities
â”œâ”€â”€ ğŸ“‹ requirements.txt       # Python dependencies
â”œâ”€â”€ ğŸ³ Dockerfile             # Container deployment
â”œâ”€â”€ âš™ï¸ .gitignore             # Git ignore rules
â””â”€â”€ ğŸ“– README.md              # This file
```


---

## ğŸš€ Quick Start (5 Minutes)

### Prerequisites

- **Python 3.11+** installed
- **8GB RAM** minimum (16GB recommended)
- **2GB free disk space**

### Steps

```bash
git clone https://github.com/regnna/semantic-search-using-GPT.git
cd semantic-search-using-GPT

# Run Ollama in Docker
docker run -d -v ollama:/root/.ollama -p 11434:11434 --name ollama ollama/ollama

# Pull model inside container
docker exec -it ollama ollama pull llama3.2

# Run your app (in another terminal)
streamlit run app.py